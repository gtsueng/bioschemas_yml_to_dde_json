{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDE-compatible json converter\n",
    "\n",
    "This script converts ingests the yml files and outputs jsonschema that should be mostly DDE-compatible. Note that there are exceptions as some missing logic is not yet in place. The DDE already has a copy of schema.org ingested; hence, it should not be necessary to include enums of all schema.org classes in the validation.\n",
    "\n",
    "Note that the DDE intends to make schemas more human interpretable; hence, it does NOT like excessive nesting and circularity in the `$validation` portion of the jsonschema. While infinite, looping, references are allowed in schema.org, it can cause errors if enforced in the `$validation` portion. To bypass this, extensive nesting has been avoided by including simplified classes as objects in the definitions portion of the `$validation`. Although these simplified objects may not include ALL the properties allowable for that class, it should not raise errors if they are included during validation either.   \n",
    "\n",
    "Already in place:\n",
    "* If a property comes from bioschemas, it will need to be defined in the @graph\n",
    "* If a property exists in the hierarchy and can be inherited, then it should not need to be defined. Instead, it should be defined in the `$validation`\n",
    "\n",
    "If a property comes from schema.org it may or may not be need to be defined. This depends on whether or not the property exists in the hierarchy from which this class is derived. This is because the only real constraints provided by schema.org are class hierarchies and property<->class relationships. Hence, the DDE only allows the inheritance of properties that are within the class hierarchy. Marginality, cardinality, and other useful constraints (eg- ontologies) in the biomedical research space come from bioschemas.\n",
    "\n",
    "Not yet in place:\n",
    "* If a schema.org property does not exist in the hierarchy, it normally does not apply to this class,\n",
    "* If this is the case, it should be created with the \"sameAs\" property\n",
    "\n",
    "#### To Do:\n",
    "Some of the yaml files are throwing errors the following errors:\n",
    "`ScannerError: mapping values are not allowed here`\n",
    "Currently, we log the error and ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import pathlib\n",
    "import yaml\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "tmp_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(tmp_dir)\n",
    "available = os.listdir(parent_dir)\n",
    "outputdirectory = os.path.join(parent_dir,'specifications')\n",
    "inputdirectory = os.path.join(parent_dir,'Bioschemas-Validator')\n",
    "input_profiles = os.path.join(inputdirectory,'profile_json')\n",
    "input_marginality = os.path.join(inputdirectory,'profile_marginality')\n",
    "input_yml = os.path.join(inputdirectory,'profile_yml')\n",
    "\n",
    "specifications = os.listdir(input_profiles)\n",
    "datapath = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load the yaml file\n",
    "def get_yml_dict(theymlfile):\n",
    "    try:\n",
    "        with open(theymlfile,'r',encoding=\"utf8\") as ymlin:\n",
    "            tmpyml = yaml.load_all(ymlin, Loader=yaml.FullLoader)\n",
    "            for eachyml in tmpyml:\n",
    "                if '<!DOCTYPE HTML>' in eachyml:\n",
    "                    break\n",
    "                ymldict = eachyml\n",
    "    except:\n",
    "        with open(theymlfile,'r',encoding=\"latin1\") as ymlin:\n",
    "            tmpyml = yaml.load_all(ymlin, Loader=yaml.FullLoader)\n",
    "            for eachyml in tmpyml:\n",
    "                if '<!DOCTYPE HTML>' in eachyml:\n",
    "                    break\n",
    "                ymldict = eachyml\n",
    "    return(ymldict)\n",
    "\n",
    "\n",
    "def test_yml_mapping(ymldict):\n",
    "    if 'mapping' in ymldict.keys():\n",
    "        mapping=True\n",
    "    else:\n",
    "        mapping=ymldict.keys()\n",
    "    return(mapping)\n",
    "\n",
    "\n",
    "#### Create the base class\n",
    "def create_new_dict():\n",
    "    newdict = {}\n",
    "    newdict['@context'] = {\n",
    "        \"schema\": \"http://schema.org/\",\n",
    "        \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "        \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "        \"dct\": \"https://dublincore.org/specifications/dublin-core/dcmi-terms/#\",\n",
    "        \"bioschemas\": \"http://discovery.biothings.io/view/bioschemas/\"\n",
    "      } \n",
    "    return(newdict)\n",
    "\n",
    "\n",
    "def get_schema_base():\n",
    "    ## Note the DDE has been updated with the latest version\n",
    "    schemabase = 'https://raw.githubusercontent.com/schemaorg/schemaorg/main/data/releases/13.0/schemaorg-all-http.jsonld'\n",
    "    r = requests.get(schemabase)\n",
    "    schematree = r.text\n",
    "    return(schematree)\n",
    "\n",
    "\n",
    "def grab_class_info(schematree,eachversion,ymldict):\n",
    "    parentclass = ymldict['hierarchy'][-1]\n",
    "    if parentclass in schematree:\n",
    "        parenttype = \"schema:\"\n",
    "    else:\n",
    "        parenttype = \"bioschemas:\"\n",
    "    try:\n",
    "        description = ymldict['spec_info']['subtitle']+\" \"+ymldict['spec_info']['description']+\" Version: \"+ymldict['spec_info']['version']\n",
    "    except:\n",
    "        description = ymldict['spec_info']['subtitle']+\" \"+\" Version: \"+ymldict['spec_info']['version']\n",
    "    classinfo = {\n",
    "      \"@id\": \"bioschemas:\"+ymldict['name'],\n",
    "      \"@type\": \"rdfs:Class\",\n",
    "      \"rdfs:comment\": description,\n",
    "      \"schema:schemaVersion\": [\"https://bioschemas.org/\"+ymldict['spec_type'].lower()+\"s/\"+ymldict['name']+\"/\"+eachversion.replace(\".json\",\"\")],  \n",
    "      \"rdfs:label\": ymldict['name'],\n",
    "      \"rdfs:subClassOf\": {\n",
    "        \"@id\": parenttype+parentclass\n",
    "      }\n",
    "    }\n",
    "    return(classinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create the validation for the class\n",
    "\n",
    "def load_dictionaries():\n",
    "    from dde_reusable_objects import expected_type_dict\n",
    "    from dde_reusable_objects import reusable_definitions\n",
    "    return(expected_type_dict, reusable_definitions)\n",
    "\n",
    "\n",
    "def generate_type(expected_type_dict, propertytype):\n",
    "    if propertytype in expected_type_dict.keys():\n",
    "        matched_type = expected_type_dict[propertytype]\n",
    "    else:\n",
    "        matched_type = False\n",
    "    return(matched_type)\n",
    "\n",
    "\n",
    "def generate_base_dict(expectedtype):\n",
    "    base_dict = {\n",
    "        \"@type\": expectedtype,\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"  \n",
    "          }  \n",
    "        },\n",
    "        \"required\": []\n",
    "    }\n",
    "    return(base_dict)\n",
    "\n",
    "\n",
    "def import_reusable_objects(reusable_definitions,rangelist):\n",
    "    expected_types = [x[\"@id\"].replace(\"bioschemas:\",\"\") for x in rangelist]\n",
    "    all_expected_types = [x.replace(\"schema:\",\"\") for x in expected_types]\n",
    "    definitionslist = [x for x in all_expected_types if x.lower() in reusable_definitions.keys()]\n",
    "    definitiondict = {}\n",
    "    referencelist = {}\n",
    "    for eachdefinition in definitionslist:\n",
    "        definitiondict[eachdefinition.lower()] = reusable_definitions[eachdefinition.lower()]\n",
    "        referencelist[eachdefinition.lower()] = {\"$ref\":\"#/definitions/\"+eachdefinition.lower()}        \n",
    "    return(definitiondict,referencelist)\n",
    "\n",
    "\n",
    "def check_type(expected_type_dict, referencelist, definitiondict, propertytype_info):\n",
    "    referencename = propertytype_info.replace(\"bioschemas:\",\"\").replace(\"schema:\",\"\").lower()\n",
    "    matched_type = generate_type(expected_type_dict, propertytype_info)\n",
    "    if matched_type != False:\n",
    "        actualtype = matched_type\n",
    "    else:\n",
    "        if referencename in referencelist.keys():\n",
    "            actualtype = referencelist[referencename]\n",
    "        else:\n",
    "            ### create reference and property\n",
    "            actualtype = {\"$ref\":\"#/definitions/\"+referencename}\n",
    "            referencelist[referencename] = actualtype\n",
    "            definitiondict[referencename] = generate_base_dict(propertytype_info)    \n",
    "    return(actualtype, referencelist, definitiondict)\n",
    "\n",
    "\n",
    "def cardinality_check(expected_type_dict, referencelist, definitiondict, eachproperty):\n",
    "    rangelist = get_rangelist(eachproperty)\n",
    "    ## Generate the base object\n",
    "    if \"bsc_description\" in eachproperty.keys():\n",
    "        valpropdict = {\"description\":eachproperty['bsc_description']+\" \"+eachproperty['description']}\n",
    "    else:\n",
    "        valpropdict = {\"description\":eachproperty['description']}\n",
    "    ## Check cardinality    \n",
    "    if eachproperty['cardinality'] != \"MANY\": ## There can only be one expected value or cardinality not defined\n",
    "        ## Check number of expected types\n",
    "        if len(rangelist) == 1: ## There can only be one expected type\n",
    "            propertytype = rangelist[0]\n",
    "            actualtype, referencelist, definitiondict = check_type(expected_type_dict, referencelist, definitiondict, propertytype['@id'])\n",
    "            valpropdict.update(actualtype)\n",
    "        else: ## There are more than one expected type\n",
    "            propertyelements = []\n",
    "            for propertytype in rangelist:\n",
    "                actualtype, referencelist, definitiondict = check_type(expected_type_dict, referencelist, definitiondict, propertytype['@id'])\n",
    "                if actualtype not in propertyelements:\n",
    "                    propertyelements.append(actualtype)\n",
    "            valpropdict[\"oneOf\"] = propertyelements\n",
    "                \n",
    "    else: ## each property can have many elements, ie- Cardinality == Many\n",
    "        ## Check number of expected types\n",
    "        if len(rangelist) == 1: ## If only one type expected, but many of it are allowed\n",
    "            propertytype = rangelist[0]\n",
    "            actualtype, referencelist, definitiondict = check_type(expected_type_dict, referencelist, definitiondict, propertytype['@id'])\n",
    "            valpropdict[\"oneOf\"] = [\n",
    "                  actualtype,\n",
    "                  {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": actualtype\n",
    "                  }\n",
    "              ]  \n",
    "        else: ## Many types are allowed, and many values are expected\n",
    "            propertyelements = []\n",
    "            for propertytype in rangelist:\n",
    "                actualtype, referencelist, definitiondict = check_type(expected_type_dict, referencelist, definitiondict, propertytype['@id'])\n",
    "                if actualtype not in propertyelements:\n",
    "                    propertyelements.append(actualtype)\n",
    "                manyactualtype = {\"type\":\"array\", \"items\":actualtype}\n",
    "                if manyactualtype not in propertyelements:\n",
    "                    propertyelements.append(manyactualtype)\n",
    "            valpropdict[\"anyOf\"] = propertyelements            \n",
    "    return(valpropdict, referencelist, definitiondict)\n",
    "\n",
    "\n",
    "#### Generate validation content\n",
    "\n",
    "def generate_validation(ymldict):\n",
    "    expected_type_dict, reusable_definitions = load_dictionaries()\n",
    "    propertylist = ymldict['mapping']\n",
    "    validationdict = {\n",
    "      \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "      \"type\": \"object\",\n",
    "      \"properties\":{},\n",
    "      \"required\":[],\n",
    "      \"recommended\":[],\n",
    "      \"optional\":[],\n",
    "      \"definitions\":{}\n",
    "    }\n",
    "    for eachproperty in propertylist:\n",
    "        rangelist = get_rangelist(eachproperty)\n",
    "        definitiondict,referencelist = import_reusable_objects(reusable_definitions,rangelist)\n",
    "        valpropdict, referencelist, definitiondict = cardinality_check(expected_type_dict, referencelist, definitiondict, eachproperty)\n",
    "        actualname, property_source = split_property_name(eachproperty[\"property\"])\n",
    "        validationdict[\"properties\"][actualname]=valpropdict\n",
    "        validationdict['definitions'].update(definitiondict)\n",
    "        #### Include categorycode if propertyvalue is used\n",
    "        if \"propertyvalue\" in validationdict['definitions'].keys():\n",
    "            validationdict['definitions']['categorycode']=reusable_definitions[\"categorycode\"]\n",
    "        #### Include definedTermSet if definedTerm is used\n",
    "        if \"definedterm\" in validationdict['definitions'].keys():\n",
    "            validationdict['definitions']['definedtermset']=reusable_definitions[\"definedtermset\"]\n",
    "        #### Include creativework if person is used (but only if it isn't already included)\n",
    "        if \"person\" in validationdict['definitions'].keys():\n",
    "            if \"creativework\" not in validationdict['definitions'].keys():\n",
    "                validationdict['definitions']['creativework']=reusable_definitions['creativework']\n",
    "        try:\n",
    "            marginality = eachproperty[\"marginality\"]\n",
    "        except:\n",
    "            marginality = None\n",
    "        if marginality == \"Minimum\":\n",
    "            validationdict['required'].append(actualname)\n",
    "        elif marginality == \"Recommended\":\n",
    "            validationdict['recommended'].append(actualname)\n",
    "        elif marginality == \"Optional\":\n",
    "            validationdict['optional'].append(actualname)\n",
    "    return(validationdict)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define properties for the graph\n",
    "\n",
    "def check_property_source(eachproperty): \n",
    "    if eachproperty['type']==\"bioschemas\":\n",
    "        namespace = \"bioschemas\"\n",
    "    elif eachproperty['type']==\"external\":\n",
    "        namespace = \"TBD\"\n",
    "    else:\n",
    "        namespace = \"schema\"\n",
    "    return(namespace)\n",
    "\n",
    "def get_rangelist(eachproperty):\n",
    "    typelist = eachproperty['expected_types']\n",
    "    bioschemalist = [x for x in typelist if x in specifications]\n",
    "    expected_bioschemas = [\"bioschemas:\"+x for x in bioschemalist]\n",
    "    expected_schemas = [\"schema:\"+x for x in typelist if x not in bioschemalist]\n",
    "    rangelist = [{\"@id\":x} for x in expected_bioschemas]\n",
    "    for x in expected_schemas:\n",
    "        rangelist.append({\"@id\":x})\n",
    "    return(rangelist)\n",
    "\n",
    "def get_domain(eachspec):\n",
    "    domain = {\"@id\":\"bioschemas:\"+eachspec}\n",
    "    return(domain)\n",
    "\n",
    "\n",
    "def split_property_name(propertyname):\n",
    "    try:\n",
    "        propertynameinfo = propertyname.split(\":\")\n",
    "        property_source = propertynameinfo[0]\n",
    "        actualname = propertynameinfo[1]\n",
    "    except:\n",
    "        actualname = propertyname\n",
    "        property_source = None\n",
    "    return(actualname, property_source)\n",
    "\n",
    "\n",
    "def create_bioschema_property(eachspec, eachproperty):\n",
    "    domain = get_domain(eachspec)\n",
    "    rangelist = get_rangelist(eachproperty)\n",
    "    namespace = check_property_source(eachproperty)\n",
    "    source4context = False\n",
    "    if namespace==\"bioschemas\":\n",
    "        ### Create property\n",
    "        try:\n",
    "            description = eachproperty[\"description\"]+\" \"+eachproperty['bsc_description']\n",
    "        except:\n",
    "            description = eachproperty[\"description\"]\n",
    "        property_dict = {\n",
    "            \"@id\": \"bioschemas:\"+eachproperty['property'],\n",
    "            \"rdfs:comment\": description,\n",
    "            \"@type\": \"rdf:Property\",\n",
    "            \"rdfs:label\": eachproperty['property'],\n",
    "            \"schema:domainIncludes\": domain,\n",
    "            \"schema:rangeIncludes\": rangelist\n",
    "        }\n",
    "    elif namespace==\"TBD\":\n",
    "        ### Create externally referencing property\n",
    "        try:\n",
    "            description = eachproperty[\"description\"]+\" \"+eachproperty['bsc_description']\n",
    "        except:\n",
    "            description = eachproperty[\"description\"]\n",
    "        actualname, propertysource = split_property_name(eachproperty['property'])\n",
    "        property_dict = {\n",
    "            \"@id\": eachproperty['property'],\n",
    "            \"rdfs:comment\": description,\n",
    "            \"@type\": \"rdf:Property\",\n",
    "            \"rdfs:label\": actualname,\n",
    "            \"schema:domainIncludes\": domain,\n",
    "            \"schema:rangeIncludes\": rangelist\n",
    "        }\n",
    "        if propertysource != None:\n",
    "            source4context = {propertysource:eachproperty[\"type_url\"].replace(actualname,'')}\n",
    "    else:\n",
    "        property_dict = False\n",
    "    return(property_dict,source4context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assemble the jsonld file\n",
    "\n",
    "def parse_spec_version(tmpinputyml,eachversion,eachspec,specifications):\n",
    "    theymlfile = os.path.join(tmpinputyml,eachversion.replace('.json','.html'))\n",
    "    graphlist = []\n",
    "    tmpdict = create_new_dict()\n",
    "    ymldict = get_yml_dict(theymlfile)\n",
    "    schematree = get_schema_base()\n",
    "    classinfo = grab_class_info(schematree,eachversion,ymldict)\n",
    "    expected_type_dict, reusable_definitions = load_dictionaries()\n",
    "    mapping = test_yml_mapping(ymldict)\n",
    "    if mapping == True:\n",
    "        propertylist = ymldict['mapping']\n",
    "        validationdict = generate_validation(ymldict)\n",
    "        classinfo['$validation']=validationdict\n",
    "        graphlist.append(classinfo)\n",
    "        for eachproperty in propertylist:\n",
    "            bioschemaprop,source4context = create_bioschema_property(eachspec, eachproperty)\n",
    "            if bioschemaprop != False:\n",
    "                graphlist.append(bioschemaprop)\n",
    "            if source4context != False:\n",
    "                tmpdict['@context'].update(source4context)\n",
    "        tmpdict['@graph']=graphlist\n",
    "    else:\n",
    "        print(mapping)\n",
    "        tmpdict=False\n",
    "    return(tmpdict)\n",
    "\n",
    "\n",
    "#### Parse specifications\n",
    "def parse_for_dde(input_profiles,datapath,test=False):\n",
    "    specifications = os.listdir(input_profiles)\n",
    "    failures = []\n",
    "    if test==True:\n",
    "        eachspec = specifications[-4] ##TaxonRank (-3), LabProtocol (14), Course (5)\n",
    "        tmpinputprofilepath = os.path.join(input_profiles,eachspec)\n",
    "        tmpinputyml = os.path.join(input_yml,eachspec)\n",
    "        spec_profs = os.listdir(tmpinputprofilepath)\n",
    "        eachversion = spec_profs[-1]\n",
    "        tmpdict = parse_spec_version(tmpinputyml,eachversion,eachspec,specifications)\n",
    "        if os.path.exists(os.path.join(datapath,str(eachspec)))==False:\n",
    "            os.makedirs(os.path.join(datapath,str(eachspec)))\n",
    "        outputpath = os.path.join(datapath,str(eachspec))\n",
    "        with open(os.path.join(outputpath,str(eachspec)+'_v'+str(eachversion)),\"w+\") as outfile:\n",
    "            outfile.write(json.dumps(tmpdict, indent=4, sort_keys=False))\n",
    "    else:\n",
    "        for eachspec in specifications:\n",
    "            tmpinputprofilepath = os.path.join(input_profiles,eachspec)\n",
    "            tmpinputyml = os.path.join(input_yml,eachspec)\n",
    "            spec_profs = os.listdir(tmpinputprofilepath)\n",
    "            for eachversion in spec_profs:\n",
    "                try:\n",
    "                    tmpdict = parse_spec_version(tmpinputyml,eachversion,eachspec,specifications)\n",
    "                except:\n",
    "                    tmpdict=False\n",
    "                    failures.append(\"error parsing yml for: \"+str(eachspec)+'_v'+str(eachversion))\n",
    "                if tmpdict==False:\n",
    "                    print(\"The specification: \",str(eachspec)+'_v'+str(eachversion),' does not have a mapping in the yaml')\n",
    "                    failures.append(\"no mapping in yml for: \"+str(eachspec)+'_v'+str(eachversion))\n",
    "                else:\n",
    "                    if os.path.exists(os.path.join(datapath,str(eachspec)))==False:\n",
    "                        os.makedirs(os.path.join(datapath,str(eachspec)))\n",
    "                    outputpath = os.path.join(datapath,str(eachspec))\n",
    "                    with open(os.path.join(outputpath,str(eachspec)+'_v'+str(eachversion)),\"w+\") as outfile:\n",
    "                        outfile.write(json.dumps(tmpdict, indent=4, sort_keys=False))\n",
    "        with open(os.path.join(datapath,'failures.txt'),'w+') as failurelog:\n",
    "            for eachitem in failures:\n",
    "                failurelog.write(eachitem+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i < len(specifications):\n",
    "    print(i, specifications[i])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect a dictionary parsed from the yaml file\n",
    "#print(specifications)\n",
    "eachspec = specifications[14] ##TaxonRank (-3), LabProtocol (14), Course (5)\n",
    "tmpinputprofilepath = os.path.join(input_profiles,eachspec)\n",
    "tmpinputmarginpath = os.path.join(input_marginality,eachspec)\n",
    "tmpinputyml = os.path.join(input_yml,eachspec)\n",
    "spec_profs = os.listdir(tmpinputprofilepath)\n",
    "eachversion = spec_profs[-1]\n",
    "thejsonfile = os.path.join(tmpinputprofilepath,eachversion)\n",
    "themarginfile = os.path.join(tmpinputmarginpath,eachversion)\n",
    "theymlfile = os.path.join(tmpinputyml,eachversion.replace('.json','.html'))\n",
    "#print(os.listdir(tmpinputyml))\n",
    "#print(theymlfile)\n",
    "\n",
    "ymldict = get_yml_dict(theymlfile)\n",
    "print(ymldict.keys())\n",
    "i = 0\n",
    "print(ymldict['mapping'][0].keys())\n",
    "#mapping = test_yml_mapping(ymldict)\n",
    "#print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do a test run\n",
    "parse_for_dde(input_profiles,datapath,test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'previous_version', 'previous_release', 'status', 'spec_type', 'group', 'use_cases_url', 'cross_walk_url', 'gh_tasks', 'live_deploy', 'parent_type', 'hierarchy', 'spec_info'])\n",
      "The specification:  Journal_v0.1-DRAFT-2019_01_29.json  does not have a mapping in the yaml\n",
      "The specification:  Organization_v0.2-DRAFT-2019_07_17.json  does not have a mapping in the yaml\n",
      "The specification:  Sample_v0.1-DRAFT-2018_02_25.json  does not have a mapping in the yaml\n",
      "The specification:  Sample_v0.2-DRAFT-2018_11_09.json  does not have a mapping in the yaml\n",
      "The specification:  Sample_v0.2-DRAFT-2018_11_10.json  does not have a mapping in the yaml\n",
      "The specification:  Sample_v0.2-RELEASE-2018_11_10.json  does not have a mapping in the yaml\n",
      "The specification:  Tool_v0.3-DRAFT-2018_11_21.json  does not have a mapping in the yaml\n",
      "The specification:  Tool_v0.3-DRAFT-2019_07_18.json  does not have a mapping in the yaml\n",
      "The specification:  TrainingMaterial_v0.7-DRAFT-2019_11_08.json  does not have a mapping in the yaml\n"
     ]
    }
   ],
   "source": [
    "## Run through all specifications\n",
    "parse_for_dde(input_profiles,datapath,test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
